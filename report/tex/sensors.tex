\chapter{Sensors}

\section{Introduction}
Modern smartphones have many sensors, and most of them can extend robot's
functionality.
Sensors differ between phones, and new (or more advanced) ones can
be connected using possible connections (mostly USB and Bluetooth).
Most popular ones are:
\begin{itemize}
  \item touch screen,
  \item accelerometer,
  \item gyroscope,
  \item microphone(s),
  \item front and rear camera(s),
  \item position sensors:
  \begin{itemize}
    \item GPS,
    \item multilateration based on GSM and/or WiFi,
  \end{itemize}
  \item magnetometer,
  \item light sensor,
  \item proximity sensor.
\end{itemize}
Some (mostly high-end, or specialized ones) smartphones have also sensors like
electronic compass, humidity/temperature sensors, fingerprint scanner, or even
thermal camera.

One of possible application can be using one of cameras for face detection, and
then turning robot around to make it directly at front. 
Such functionality was implemented for ``Face Follower'' (img. \ref{img:SoA0})
developed for one of previous projects. 
It was using ``full'' version of OpenCV in C++. 
Because Android is a different platform, the same method couldn't be used for
it.
Fortunately, Android offers few different ways to do it, including:
\begin{itemize}
  \item FaceDetector API,
  \item Camera API,
  \item OpenCV for Android (Java and NDK),
\end{itemize}
All methods are described in their own sections, and results are aggregated in
table in summary sections. 
During development, search results for ``face'' on Google were used, and final
results were obtained on image from \cite{faces}, shown on img. \ref{img:faces}.

\includeimage[0.7]{faces}{Image used for testing face detection}

\section{FaceDetector API}
First method is FaceDetector API, which is part of Android environment.
Usage is simple (listing \ref{lst:fdapi}) but the problem is, that it requires
image as a Bitmap, which is hard to get from a camera.
\lstinputlisting[float, label=lst:fdapi, caption=Face Detector API]
{../code_samples/facedetectorapi_sample.java}
Obtaining frame as a Bitmap actually takes more time than detecting faces on it,
so it was tested on image already in memory.
Result is shown on img. \ref{img:facedetectorapi} - it can be seen, that it's
possible to detect many faces (on this image: all 20).
Unfortunately, Android Reference \cite{android_reference} doesn't describe, how
face detection is done.

Summing up, this API is rather for working on photos, not video, also
because it has rather weak performance.

\includeimage[0.4]{facedetectorapi}{Face Detector API}

\section{Camera API}
Next method is CameraAPI, which is also part of Android, and fortunately allows
for easy working with camera preview (but still, it's not described, how
detection actually works).
Actually, it's an API to access camera, and face detecting is only part of it.
This API is now also deprecated and replaced with Camera2 API, but because newer
one doesn't work with older Android versions (like version on Xperia Neo), older
one was used. 
Configuration of preview is a little complicated, but after that,
face detection requires only starting it, and defining a method, which should be
invoked on each detection. Example is shown in listing \ref{lst:cameraapi}.
\lstinputlisting[float, label=lst:cameraapi, caption=Camera API]
{../code_samples/cameraapi_sample.java}

Big plus is a fact, that detection automatically happens in background, so it
doesn't freeze application, and that it runs fast (real-time on Moto G).
On the other hand, it is hard to visualize effects, so during tests it only
logged result (position, number of detected faces) to console.
In opposition to FaceDetector API, Camera API is able to found only up to 5
faces.

\section{OpenCV for Android}
% detection in user's code
Original robot was using OpenCV library on Windows, and it's also available for
Android, written in Java (actually, only interface is in Java, and there is
C++ below it).
Similarly to Windows, it's also hard to make it work, but when it's done, it offers a lot of capabilities.

It's possible to override method invoked on each frame (listing
\ref{lst:opencv}), and then do e.g. face detection on it.
Such approach was not possible in Camera API - it was possible to invoke method
on each frame, but its face detection couldn't be used in such case.
OpenCV offers more control, and allows for doing more things with images,
because it's a whole library created for that matter.
It has methods to look for patterns on image using, e.g. Haar cascades.
It's possible to create own ones, but library also provides several pre-defined
ones - few different for faces, for eyes, even for face of a cat.
In sample code, detection freezes application, but because it's possible to
control, when and how it's invoked, it's possible to do it in separate thread
(which was actually done) or even work on few frames simultaneously.

It's also easy to visualize effects on preview for camera. Results for high and
low resolution can be found on img. \ref{img:opencv_high} and
\ref{img:opencv_low}.
As it can be seen, even for really small resolution, quality of detection is
still quite good, and it was almost 15 times faster (\textasciitilde1500 ms vs
105 ms).
There is also no (or very high) limit for maximum number of detected faces.

\lstinputlisting[float, label=lst:opencv, caption=OpenCV]
{../code_samples/opencv_sample.java}

\includeimage{opencv_high}{openCV - high resolution}
[\\All faces were detected, but also false matches can be seen. Faces were
always found, and false matches occurred only from time to time.]

\includeimage{opencv_low}{openCV - low resolution}
[\\Not all faces were detected, but there's also no false matches. Frame
around face has the same width (3px) as on previous image, so resolution is
really small.]

\section{OpenCV NDK}
OpenCV on Android has also NDK (Native Development Kit) version.
Using NDK instead of normal Android's SDK offers better performance, but working
with it is much more complicated.

Unfortunately, Android Studio still have problems with development of NDK, and
most tutorials to it focuses on older Eclipse ADT. 
OpenCV provides some example projects using NDK (and face detector is one of
them), but they are created also for Eclipse ADT.

Therefore, it wasn't implemented and tested. 
Fortunately, there is already built example of Face Detector on Google Play, so
it was possible to see, how it works (img. \ref{img:opencv_ndk}). 
It was impossible to measure time needed for
detection, but it seemed to be (almost) smooth, so probably about 50 ms for
frame with quite high resolution (also unknown).
\includeimage{opencv_ndk}{openCV - NDK}
[\\Application has limited screen area, so only 3 rows fitted. False matches
also occurred, and not all faces were discovered correctly, but detection was
working in almost real-time, and quality is still high.]

\section{Summary}
To compare performance of each method, they should be tested in the same
conditions. 
Therefore, the same image (\ref{img:faces}) was used for all of them.
Then, they were tested for different resolutions.
During configuration of Camera API example, list of available preview size for
both smartphones was obtained:
\begin{center}
\begin{tabular}{r@{ x }l|r@{ x }l}
\multicolumn{2}{c|}{Moto G} & \multicolumn{2}{c}{Xperia Neo} \\
\hline
1280 & 960 & 1600 & 1200 \\
1280 & 720 & 1280 & 720 \\
960 & 720 & 864 & 480 \\
864 & 480 & 640 & 480 \\
768 & 432 & 480 & 320 \\
720 & 480 & 352 & 288 \\
640 & 480 & 320 & 240 \\
320 & 240 & 176 & 144 \\
176 & 144 \\
\end{tabular}
\end{center}
As it can be seen, some resolutions are available for both smartphones, so they
were the ones used during testing of Camera API. 
However, they couldn't be used for other methods.
Face Detector API doesn't work on camera preview, so file with the same faces
was used, and scaled to have the same height as resolutions available to Camera API. 
On the other hand, in OpenCV only maximum width and height could be set, so it
was set to the same as in Camera API, but actual resolution could be a little
smaller.
Methods working on camera preview were tested with image displayed on a FullHD
computer display.

Average time needed for calculating single frame looks as follows (all values
are in milliseconds):
\begin{center}
\begin{tabular}{r@{ x }l|r|r|r|r|r|r}
\multicolumn{2}{c|}{} & \multicolumn{3}{c|}{Xperia Neo} &
\multicolumn{3}{c}{Moto G}
\\
\multicolumn{2}{c|}{} & \hspace{4ex}FD & Camera & OpenCV & \hspace{4ex}FD &
Camera & OpenCV
\\
\hline 1280 & 720 & 420 & 180 & - & 380 & 33 & 1500 \\
864 & 480 & 390 & 110 & - & 320 & 33 & 1200 \\
640 & 480 & 390 & 123 & 5000 & 320 & 33 & 1000 \\
320 & 240 & - & 128 & 2500 & - & - & 275 \\
176 & 144 & - & 101 & 500 & - & - & 105
\end{tabular}
\end{center}
As it can be seen, Camera API was the fastest. 
FaceDetector API was also fast, because its time was measured only for face
detection, and obtaining it required much more time.
OpenCV was slow, but in lower resolutions offered best quality.
It can also be seen, that Moto G is executing exactly the same code about 5
times faster.

Each method has its advantages and disadvantages, and different method can be
used, depending on requirements:
\begin{itemize}
  \item FaceDetector API:
  	\begin{itemize}
  	  \item[$+$] easy to use,
  	  \item[$+$] can work on image other than camera preview,
  	  \item[$+$] no face limit,
  	  \item[$+$] no external libraries,
  	  \item[$-$] poor performance,
  	  \item[$-$] hard to make it work with camera,
  	\end{itemize}
  \item Camera API:
	\begin{itemize}
  	  \item[$+$] easy to use,
  	  \item[$+$] doesn't freeze application,
  	  \item[$+$] no external libraries,
  	  \item[$+$] really fast,
  	  \item[$-$] max 5 faces
  	  \item[$+$] hard to visualize result on preview,
  	\end{itemize}
  \item OpenCV (Java):
	\begin{itemize}
  	  \item[$+$] allows for much more than face detection,
  	  \item[$+$] acceptable performance, especially for lower resolution,
  	  \item[$+$] no face limit,
  	  \item[$+$] easy to visualize results,
  	  \item[$+$] more control in developer's code,
  	  \item[$-$] more control in developer's code,
  	  \item[$-$] external library, hard to make it work,
  	  \item[$-$] slower than Camera API,
  	\end{itemize}
  \item OpenCV (NDK):
	\begin{itemize}
  	  \item[$+$] same as in Java, but with better performance and more control,
  	  \item[$-$] same as in Java, but much harder to work with it,
  	  \item[$-$] no Android Studio support,
  	\end{itemize}
\end{itemize}

Summing up, the best method of doing face detection is using Camera API, because
it's fastest and simplest.
FaceDetector API is inappropriate, because it's slow, and useful only for
working with already captured picture, when Camera API can't be used.

OpenCV is also a good library for face detection, but much more complex
(especially NDK), which is both huge advantage and disadvantage.
It starts being really useful, when there is a need to make something different
with an image, than face detection, because the rest offers only that.
